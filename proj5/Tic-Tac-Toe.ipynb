{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict, deque\n",
    "from itertools import product, chain\n",
    "import copy\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from IPython.display import clear_output, display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_board(board):\n",
    "    \"\"\"return string representation of board\"\"\"\n",
    "    retval = ''\n",
    "    for i, row in enumerate(board):\n",
    "        if i:\n",
    "            retval += \"===========\\n\"\n",
    "        retval += \" %s\\n\" % \" | \".join(row)\n",
    "    retval += \"\\n\"\n",
    "    return retval\n",
    "\n",
    "def print_board_html(board):\n",
    "    \"\"\"return string representation of board\"\"\"\n",
    "    retval = '<style>table, th, td {border: 1px solid black;}</style>'\n",
    "    retval += '<table>'\n",
    "    for i, row in enumerate(board):\n",
    "        retval += '<tr><td>'\n",
    "        retval += ' %s ' % \"</td><td>\".join([\" &nbsp; &nbsp; \" if p==' ' else p for p in row])\n",
    "        retval += \"</td></tr>\"\n",
    "    retval += \"</table>\"\n",
    "    return retval\n",
    "\n",
    "win_initialized=False\n",
    "def print_board_win(g, outstr=\"\"):\n",
    "    \"\"\"print in new window, open it up the first time called\"\"\"\n",
    "    global win_initialized\n",
    "    s  = '<script type=\"text/Javascript\">'\n",
    "    if not win_initialized:\n",
    "        s += 'var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=200, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));'\n",
    "        win_initialized=True\n",
    "    s += 'win.document.body.innerHTML = \\'' + print_board_html(g.board) + '<br/>' + outstr + '\\';'\n",
    "    s += '</script>'\n",
    "    return HTML(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   |   |  \n",
       "===========\n",
       "   |   |  \n",
       "===========\n",
       "   |   |  \n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOARD_SIZE = 3\n",
    "MAX_MOVES = BOARD_SIZE * BOARD_SIZE\n",
    "INIT_BOARD = ((' ',' ',' '),(' ',' ',' '),(' ',' ',' '),)\n",
    "\n",
    "class Game:\n",
    "    \"\"\"Maintain game state\"\"\"\n",
    "    \n",
    "    def __init__(self, startplayer='X'):\n",
    "        self.board = INIT_BOARD\n",
    "        self.player = startplayer\n",
    "        self.history = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"string representation of board\"\"\"\n",
    "        return print_board(self.board)\n",
    "        \n",
    "    def play(self, move, record=True):\n",
    "        \"\"\"given move as row, col, player tuple, update board\n",
    "        record=True: update game state and return board; \n",
    "        record=False: just return resulting board, i.e. for evaluation\n",
    "        \"\"\"\n",
    "        i, j, player = move\n",
    "        if player != self.player:\n",
    "            raise(Exception(\"play: wrong player %s\" % (player)))\n",
    "        elif i >= len(self.board) or j >= len(self.board):\n",
    "            raise(Exception(\"play: bad square coords %d, %d\" % (i,j)))\n",
    "        elif self.board[i][j] != ' ':\n",
    "            raise(Exception(\"play: move to non-empty square\"))\n",
    "        else:\n",
    "            # new tuple, same except set square = player\n",
    "            new_board = tuple(row if r != i \\\n",
    "                              else tuple(player if c==j else square for c, square in enumerate(row)) \\\n",
    "                              for r, row in enumerate(self.board))\n",
    "            if record:\n",
    "                self.board=new_board\n",
    "                self.history.append(self.board)\n",
    "                self.player = 'O' if self.player=='X' else 'X'\n",
    "                \n",
    "        return new_board\n",
    "    \n",
    "    def is_winner(self, player='X'):\n",
    "        b_a = np.array(self.board)\n",
    "        if any(all(b_a[i, :] == player) for i in range(BOARD_SIZE)):\n",
    "            return True\n",
    "        if any(all(b_a[:, j] == player) for j in range(BOARD_SIZE)):\n",
    "            return True\n",
    "        if all(np.diagonal(b_a) == player):\n",
    "            return True\n",
    "        if all(np.diagonal(np.fliplr(b_a)) == player):\n",
    "            return True\n",
    "        # no winning conditions are True\n",
    "        return False\n",
    "    \n",
    "g = Game()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " X | O | X\n",
       "===========\n",
       " O | X |  \n",
       "===========\n",
       " X |   | O\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.play((1,1,'X'))\n",
    "# some bad moves\n",
    "#g.play((2,2,'X')) # wrong player\n",
    "#g.play((1,1,'O')) # occupied square\n",
    "#g.play((3,1,'O')) # off board\n",
    "g.play((0,1,'O'))\n",
    "g.play((0,0,'X'))\n",
    "g.play((2,2,'O'))\n",
    "g.play((2,0,'X'))\n",
    "g.play((1,0,'O'))\n",
    "g.play((0,2,'X'))\n",
    "print(g.is_winner('O'))\n",
    "print(g.is_winner('X'))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "\n",
      "\n",
      "True\n",
      " X | X | X\n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "\n",
      "\n",
      "True\n",
      "   |   |  \n",
      "===========\n",
      " X | X | X\n",
      "===========\n",
      "   |   |  \n",
      "\n",
      "\n",
      "True\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      " X | X | X\n",
      "\n",
      "\n",
      "True\n",
      " X |   |  \n",
      "===========\n",
      " X |   |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "True\n",
      "   | X |  \n",
      "===========\n",
      "   | X |  \n",
      "===========\n",
      "   | X |  \n",
      "\n",
      "\n",
      "True\n",
      "   |   | X\n",
      "===========\n",
      "   |   | X\n",
      "===========\n",
      "   |   | X\n",
      "\n",
      "\n",
      "True\n",
      " X |   |  \n",
      "===========\n",
      "   | X |  \n",
      "===========\n",
      "   |   | X\n",
      "\n",
      "\n",
      "True\n",
      "   |   | X\n",
      "===========\n",
      "   | X |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check winning boards\n",
    "for bx in [((' ', ' ', ' '),(' ', ' ', ' '),(' ', ' ', ' ')),\n",
    "           (('X', 'X', 'X'),(' ', ' ', ' '),(' ', ' ', ' ')),\n",
    "           ((' ', ' ', ' '),('X', 'X', 'X'),(' ', ' ', ' ')),\n",
    "           ((' ', ' ', ' '),(' ', ' ', ' '),('X', 'X', 'X')),\n",
    "           (('X', ' ', ' '),('X', ' ', ' '),('X', ' ', ' ')),\n",
    "           ((' ', 'X', ' '),(' ', 'X', ' '),(' ', 'X', ' ')),\n",
    "           ((' ', ' ', 'X'),(' ', ' ', 'X'),(' ', ' ', 'X')),\n",
    "           (('X', ' ', ' '),(' ', 'X', ' '),(' ', ' ', 'X')),\n",
    "           ((' ', ' ', 'X'),(' ', 'X', ' '),('X', ' ', ' ')),]:\n",
    "    g.board = bx\n",
    "    print(g.is_winner('X'))\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.25\n",
    "DISCOUNT_RATE = 0.05\n",
    "EXPLORATION_RATE = 0.025 \n",
    "\n",
    "class RLagent:\n",
    "    \"\"\"Simple reinforcement learning agent\n",
    "    initialize with an array (defaultdict) with value for each board\n",
    "    select_move: given a board, determine valid moves, play move with best value \n",
    "    (or explore random move with probability EXPLORATION_RATE)\n",
    "    train: traverse all game boards in game state history, \n",
    "    update value array based on winner, discount rate, learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 game, \n",
    "                 V_dict,\n",
    "                 player='O',\n",
    "                 learning_rate=LEARNING_RATE,\n",
    "                 discount_rate=DISCOUNT_RATE,\n",
    "                 exploration_rate=EXPLORATION_RATE\n",
    "                ):\n",
    "        self.game = game\n",
    "        self.V = V_dict\n",
    "        self.player = player\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.exploration_rate = exploration_rate\n",
    "        \n",
    "    def valid_moves(self):\n",
    "        retlist = []\n",
    "        for i, row in enumerate(self.game.board):\n",
    "            for j, colval in enumerate(row):\n",
    "                if colval == ' ':\n",
    "                    move = (i,j, self.player)\n",
    "                    retlist.append(move)\n",
    "        return retlist\n",
    "\n",
    "    def select_move(self, verbose=False, exploration_rate=None):\n",
    "        \"\"\"select best scoring action, \n",
    "        if more than one have best score pick random from best\"\"\"\n",
    "        moves = self.valid_moves()\n",
    "\n",
    "        if not exploration_rate:\n",
    "            exploration_rate = self.exploration_rate\n",
    "        \n",
    "        # choose a random move some % of time specified by exploration rate\n",
    "        if random.uniform(0,1) < exploration_rate:\n",
    "            # set all scores to 0.5\n",
    "            scores = [0.5 for b in moves]\n",
    "            boards = [self.game.play(move, record=False) for move in moves]\n",
    "            if verbose:\n",
    "                print(\"Random exploration\")\n",
    "        else:\n",
    "            # look up boards without recording\n",
    "            boards = [self.game.play(move, record=False) for move in moves]\n",
    "            # look up scores\n",
    "            scores = [self.V[board] for board in boards]\n",
    "\n",
    "        if verbose:\n",
    "            for i, s in enumerate(scores):\n",
    "                print(\"%d.  %.04f\\n%s\" % (i, s, print_board(boards[i])))\n",
    "\n",
    "        # if player is X, choose highest prob of X winning else lowest prob of X winning\n",
    "        best_score = max(scores) if self.player == 'X' else min(scores)\n",
    "        # get all scores matching best\n",
    "        best_moves = [moves[i] for i, score in enumerate(scores) if score == best_score]\n",
    "        # pick one\n",
    "        return random.choice(best_moves)\n",
    "\n",
    "    def train(self):\n",
    "        # update value function based on winner at end of game\n",
    "        \n",
    "        # last board gets value of 1 if X wins, 0 if O wins, 0.5 if draw\n",
    "        reward = 1  if self.game.is_winner('X') \\\n",
    "            else -1 if self.game.is_winner('O') \\\n",
    "            else 0\n",
    "        \n",
    "        for b in reversed(self.game.history):\n",
    "            # update value of each board you see, by (learning rate %) of the way to current reward\n",
    "            old = self.V[b]\n",
    "            self.V[b] = old + (reward - old) * self.learning_rate\n",
    "            # discount reward as boards get older \n",
    "            reward = reward * (1-self.discount_rate)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"old %.04f new %.04f\\n%s\"% (old, self.V[b], print_board(b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent:\n",
    "    \"\"\"human player, get moves from input\"\"\"\n",
    "\n",
    "    def __init__(self, game, player):\n",
    "        self.game = game\n",
    "        self.player = player\n",
    "        \n",
    "    def get_dim(self, prompt):\n",
    "        \"\"\"get a single row or column input\"\"\"\n",
    "        dim = None\n",
    "        while dim not in range(1,BOARD_SIZE+1):\n",
    "            print(prompt)\n",
    "            inputstr = input()\n",
    "            dim = int(inputstr) if inputstr else -1\n",
    "        return int(dim)-1\n",
    "\n",
    "    def get_move(self):\n",
    "        while True:\n",
    "            row = self.get_dim(\"Enter row: \")\n",
    "            col = self.get_dim(\"Enter column: \")\n",
    "            try:\n",
    "                self.game.play((row, col, self.player))\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                continue\n",
    "            break\n",
    "        return row, col\n",
    "\n",
    "def play_again():\n",
    "    print('Play again? (y or n)')\n",
    "    return input().lower().startswith('y')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X |   | O\n",
      "===========\n",
      " X | O |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "X wins!\n",
      "Play again? (y or n)\n",
      "n\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "# play human v. human\n",
    "\n",
    "while True:\n",
    "    g = Game()    \n",
    "    playerX = HumanAgent(g, 'X')\n",
    "    playerO = HumanAgent(g, 'O')\n",
    "    \n",
    "    max_moves = BOARD_SIZE * BOARD_SIZE\n",
    "    winner = None\n",
    "    \n",
    "    for _ in range(max_moves):\n",
    "        clear_output()\n",
    "        print(g)\n",
    "        \n",
    "        player = g.player\n",
    "        if player == 'X':\n",
    "            row, col = playerX.get_move()\n",
    "        else:\n",
    "            row, col = playerO.get_move()\n",
    "\n",
    "        if g.is_winner(player):\n",
    "            winner = player\n",
    "            break\n",
    "\n",
    "    clear_output()\n",
    "    print(g)\n",
    "            \n",
    "    if winner is None:\n",
    "        print(\"Draw\")\n",
    "    else:\n",
    "        print(\"%s wins!\" % winner)\n",
    "\n",
    "    if not play_again():\n",
    "        print(\"Bye!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11:14:32: Game  99000 X wins: 23819 O wins 10333 Draws: 64848"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>table, th, td {border: 1px solid black;}</style><table><tr><td> X</td><td>O</td><td>X </td></tr><tr><td> X</td><td>O</td><td>X </td></tr><tr><td> O</td><td>X</td><td>O </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "# play a bunch of games computer v. computer and update V table\n",
    "\n",
    "START_EXPLORATION_RATE = 0.25\n",
    "NUM_GAMES = 99999\n",
    "V = defaultdict(lambda: 0)\n",
    "verbose = False\n",
    "\n",
    "def play_game(V,\n",
    "              board_size=BOARD_SIZE,\n",
    "              exploration_rate=START_EXPLORATION_RATE,\n",
    "              outstr=\"\",\n",
    "              show_display=True,\n",
    "              verbose=verbose):\n",
    "\n",
    "    g = Game()    \n",
    "    playerX = RLagent(g, V, 'X')\n",
    "    playerO = RLagent(g, V, 'O')\n",
    "    \n",
    "    max_moves = BOARD_SIZE * BOARD_SIZE\n",
    "    winner = None\n",
    "\n",
    "    for move_counter in range(max_moves): \n",
    "        player = g.player\n",
    "\n",
    "        if player == 'X':\n",
    "            move = playerX.select_move(verbose, exploration_rate=exploration_rate)\n",
    "        else:\n",
    "            move = playerO.select_move(verbose, exploration_rate=exploration_rate)\n",
    "        g.play(move)\n",
    "        \n",
    "        if g.is_winner(player):\n",
    "            winner = player\n",
    "            break\n",
    "\n",
    "    if show_display:\n",
    "        clear_output()\n",
    "        display(HTML(outstr))\n",
    "        display(HTML(print_board_html(g.board)))\n",
    "        #print_board_win(g)\n",
    "    #     if winner is None:\n",
    "    #         display(HTML(\"Draw\"))\n",
    "    #     else:\n",
    "    #         display(HTML(\"%s wins!\" % winner))\n",
    "\n",
    "    if verbose:\n",
    "        for i, b in enumerate(g.history):\n",
    "            print(\"Move %d\" % i)\n",
    "            print(V[b])\n",
    "            print(print_board(b))\n",
    "        \n",
    "    # update V\n",
    "    # players share V array and g game history so we can train either player, only train once\n",
    "    playerO.train()\n",
    "    \n",
    "    return winner\n",
    "\n",
    "winx, wino, draws = 0,0,0\n",
    "for game_counter in range(NUM_GAMES):\n",
    "    # linear epsilon decay\n",
    "    exploration_rate = (1 - game_counter/NUM_GAMES) * START_EXPLORATION_RATE\n",
    "\n",
    "    outstr = (\"%s: Game %6d X wins: %d O wins %d Draws: %d\" % (time.strftime(\"%H:%M:%S\"), game_counter, \n",
    "                                                                winx, wino, draws)\n",
    "              )\n",
    "\n",
    "    show_display=True if game_counter % 1000 == 0 else False\n",
    "    winner = play_game(V, exploration_rate=exploration_rate, outstr=outstr, show_display=show_display)\n",
    "    if winner == None:\n",
    "        draws +=1\n",
    "    elif winner == 'X':\n",
    "        winx +=1\n",
    "    else:\n",
    "        wino +=1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "\n",
      "\n",
      "-0.216749\n",
      "   |   |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "0.725068\n",
      "   | O |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "0.820386\n",
      " X | O |  \n",
      "===========\n",
      "   |   |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "0.856862\n",
      " X | O |  \n",
      "===========\n",
      " O |   |  \n",
      "===========\n",
      " X |   |  \n",
      "\n",
      "\n",
      "0.502721\n",
      " X | O |  \n",
      "===========\n",
      " O |   |  \n",
      "===========\n",
      " X |   | X\n",
      "\n",
      "\n",
      "0.514714\n",
      " X | O |  \n",
      "===========\n",
      " O | O |  \n",
      "===========\n",
      " X |   | X\n",
      "\n",
      "\n",
      "0.999821\n",
      " X | O |  \n",
      "===========\n",
      " O | O |  \n",
      "===========\n",
      " X | X | X\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check out a few V values\n",
    "\n",
    "b = ((' ', ' ', ' '),(' ', ' ', ' '),(' ', ' ', ' '))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = ((' ', ' ', ' '),(' ', ' ', ' '),('X', ' ', ' '))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = ((' ', 'O', ' '),(' ', ' ', ' '),('X', ' ', ' '))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = (('X', 'O', ' '),(' ', ' ', ' '),('X', ' ', ' '))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = (('X', 'O', ' '),('O', ' ', ' '),('X', ' ', ' '))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = (('X', 'O', ' '),('O', ' ', ' '),('X', ' ', 'X'))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = (('X', 'O', ' '),('O', 'O', ' '),('X', ' ', 'X'))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n",
    "b = (('X', 'O', ' '),('O', 'O', ' '),('X', 'X', 'X'))\n",
    "print(\"%f\\n%s\"% (V[b], print_board(b)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play human vs. computer and learn interactively\n",
    "\n",
    "while True:\n",
    "    g = Game()    \n",
    "    playerX = HumanAgent(g, 'X')\n",
    "    playerO = RLagent(g, V, 'O')\n",
    "    \n",
    "    max_moves = BOARD_SIZE * BOARD_SIZE\n",
    "    winner = None\n",
    "    \n",
    "    for _ in range(max_moves):\n",
    "        clear_output()\n",
    "        print(g)\n",
    "        \n",
    "        player = g.player\n",
    "        if player == 'X':\n",
    "            row, col = playerX.get_move()\n",
    "        else:\n",
    "            move = playerO.select_move(verbose=False, exploration_rate=0)            \n",
    "            g.play(move)\n",
    "\n",
    "        if g.is_winner(player):\n",
    "            winner = player\n",
    "            break\n",
    "\n",
    "    clear_output()\n",
    "    print(g)\n",
    "    if winner is None:\n",
    "        print(\"Draw\")\n",
    "    else:\n",
    "        print(\"%s wins!\" % winner)\n",
    "\n",
    "    playerO.train()\n",
    "        \n",
    "    if not play_again():\n",
    "        print(\"Bye!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export csv\n",
    "\n",
    "def v_to_dataframe(V):\n",
    "\n",
    "    z = defaultdict(list)\n",
    "\n",
    "    for s, v in V.items():\n",
    "        # flatten\n",
    "        s = tuple(chain.from_iterable(s))\n",
    "        # map s to floats\n",
    "        #s = tuple(0 if i==' ' else 1 if i=='X' else -1 for i in s)\n",
    "        #templist = z[s]\n",
    "        #templist.append(v)\n",
    "        z[s]=v\n",
    "        \n",
    "    Vdf = pd.DataFrame(z.keys())\n",
    "    Vdf['val']=z.values()\n",
    "    return Vdf\n",
    "\n",
    "Vdf = v_to_dataframe(V)\n",
    "Vdf.to_csv('V.csv')\n",
    "Vdf.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V_from_csv(filename):\n",
    "    Vdf = pd.read_csv(filename)\n",
    "    Vdf = Vdf[['0', '1', '2', '3', '4', '5', '6', '7', '8', 'val']]\n",
    "    z = defaultdict(lambda: 0.5)\n",
    "    # make rows into tuples \n",
    "    for row in range(len(Vdf)):\n",
    "        b = ((Vdf.iloc[row][0], Vdf.iloc[row][1], Vdf.iloc[row][2]),\n",
    "             (Vdf.iloc[row][3], Vdf.iloc[row][4], Vdf.iloc[row][5]),\n",
    "             (Vdf.iloc[row][6], Vdf.iloc[row][7], Vdf.iloc[row][8]),\n",
    "            )\n",
    "        z[b] = Vdf.iloc[row]['val']\n",
    "    return Vdf\n",
    "\n",
    "Vdf = V_from_csv('V.csv')\n",
    "Vdf.head()\n",
    "\n",
    "# pickle would have been easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent that uses neural network instead of lookup table/linear model\n",
    "\n",
    "LEARNING_RATE = 0.4\n",
    "DISCOUNT_RATE = 0.05\n",
    "EXPLORATION_RATE = 0.1\n",
    "QUEUE_LEN = 1000\n",
    "INPUT_DIM=9\n",
    "\n",
    "# V_hist_columns=['0','1','2','3','4','5','6','7','8','val']\n",
    "# V_hist = pd.DataFrame(columns=V_hist_columns)\n",
    "\n",
    "class DeepRLagent:\n",
    "    \"\"\"Instead of updating a V dict in training, add experienced reward values to dataframe\n",
    "    and train neural net to predict boards based on the experienced values\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 game, \n",
    "                 V_model,\n",
    "                 V_hist,\n",
    "                 player='O',\n",
    "                 discount_rate=DISCOUNT_RATE,\n",
    "                 exploration_rate=EXPLORATION_RATE\n",
    "                ):\n",
    "        self.game = game\n",
    "        self.player = player\n",
    "        self.discount_rate = discount_rate\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.V_hist = V_hist\n",
    "        self.V_model = V_model\n",
    "        self.best_metric = None\n",
    "        self.best_model = None\n",
    "        \n",
    "    def valid_moves(self):\n",
    "        retlist = []\n",
    "        for i, row in enumerate(self.game.board):\n",
    "            for j, colval in enumerate(row):\n",
    "                if colval == ' ':\n",
    "                    move = (i,j, self.player)\n",
    "                    retlist.append(move)\n",
    "        return retlist\n",
    "\n",
    "    def select_move(self, verbose=False, exploration_rate=None):\n",
    "        \"\"\"select best scoring action, \n",
    "        if more than one have best score pick random from best\"\"\"\n",
    "        moves = self.valid_moves()\n",
    "\n",
    "        if not exploration_rate:\n",
    "            exploration_rate = self.exploration_rate\n",
    "        \n",
    "        # choose a random move some % of time specified by exploration rate\n",
    "        if random.uniform(0,1) < exploration_rate: #or not hasattr(self.V_model, 'coefs_'):\n",
    "            # set all scores to 0.5\n",
    "            scores = [0.5 for b in moves]\n",
    "            boards = [self.game.play(move, record=False) for move in moves]\n",
    "            if verbose:\n",
    "                print(\"Random exploration\")\n",
    "        else:\n",
    "            # look up boards without recording\n",
    "            boards = [self.game.play(move, record=False) for move in moves]\n",
    "            # look up scores\n",
    "            flatboards = [np.array(self.flatten(b)).reshape(1,-1) for b in boards]\n",
    "            scores = [self.V_model.predict(b) for b in flatboards]\n",
    "\n",
    "        if verbose:\n",
    "            for i, s in enumerate(scores):\n",
    "                print(\"%d.  %.04f\\n%s\" % (i, s, print_board(boards[i])))\n",
    "\n",
    "        # if player is X, choose highest prob of X winning else lowest prob of X winning\n",
    "        best_score = max(scores) if self.player == 'X' else min(scores)\n",
    "        # get all scores matching best\n",
    "        best_moves = [moves[i] for i, score in enumerate(scores) if score == best_score]\n",
    "        # pick one\n",
    "        return random.choice(best_moves)\n",
    "\n",
    "    def flatten(self, b):\n",
    "        \"\"\"convert board to a flat array of ints representation\"\"\"\n",
    "        #flatten\n",
    "        retlist = list(chain.from_iterable(b))\n",
    "        # convert to ints\n",
    "        retlist = [1 if player == 'X' else -1 if player=='O' else 0 for player in retlist]\n",
    "        return retlist\n",
    "    \n",
    "    def train(self, initial_epoch=0, evaluate=False):\n",
    "        # update value function based on winner at end of game\n",
    "        \n",
    "        # last board gets value of 1 if X wins, 0 if O wins, 0.5 if draw\n",
    "        reward = 1  if self.game.is_winner('X') \\\n",
    "            else -1 if self.game.is_winner('O') \\\n",
    "            else 0\n",
    "        \n",
    "        for b in reversed(self.game.history):\n",
    "            # append board, reward to queue/pandas dataframe\n",
    "            # flatten\n",
    "            observation = self.flatten(b)\n",
    "            observation.append(reward)\n",
    "            #append in place\n",
    "            self.V_hist.loc[self.V_hist.shape[0]]=observation\n",
    "            # discount value as boards get older \n",
    "            reward = reward * (1-self.discount_rate)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"new reward %.04f\\n%s\"% (reward, print_board(b)))\n",
    "        train_X = self.V_hist.iloc[-10000:,:9]\n",
    "        train_y = self.V_hist.iloc[-10000:,-1]\n",
    "        self.V_model.fit(train_X,\n",
    "                         train_y,\n",
    "                         batch_size=self.V_hist.shape[0], \n",
    "                         initial_epoch=0,\n",
    "                         epochs=1,\n",
    "                         verbose=0\n",
    "                        )\n",
    "        if evaluate:\n",
    "            train_y_predict = self.V_model.predict(train_X)\n",
    "            mse = mean_squared_error(train_y, train_y_predict)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(train_y, train_y_predict)\n",
    "            print(\"MSE: %.4f RMSE %.4f MAE %.4f\" % (mse, \n",
    "                                                    np.sqrt(mse), \n",
    "                                                    mae))            \n",
    "            global best_metric, best_model\n",
    "            if best_model is None or mae < best_metric:\n",
    "                best_model = copy.copy(V_model)\n",
    "                best_metric = mae\n",
    "                save_model('model')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ols_model(input_size = INPUT_DIM, \n",
    "                    n_hidden_layers=1, \n",
    "                    largest_layer_size=32, \n",
    "                    activation='relu',\n",
    "                    reg_penalty=0.0,\n",
    "                    dropout=False,\n",
    "                    verbose=True\n",
    "                   ):\n",
    "\n",
    "    model = Sequential()\n",
    "    hidden_layer_size=largest_layer_size\n",
    "\n",
    "    for i in range(n_hidden_layers):\n",
    "        if verbose:\n",
    "            print(\"layer %d size %d, %s, reg_penalty %.8f, dropout %.3f\" % (i + 1, \n",
    "                                                                            hidden_layer_size, \n",
    "                                                                            activation,\n",
    "                                                                            reg_penalty,\n",
    "                                                                            dropout,\n",
    "                                                                           ))\n",
    "        if i and dropout:\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "        if i==0: # first layer, specify input shape\n",
    "            model.add(Dense(input_shape=(input_size,),\n",
    "                            units = hidden_layer_size, \n",
    "                            activation = activation,\n",
    "                            kernel_initializer = keras.initializers.glorot_uniform(),\n",
    "                            kernel_regularizer=keras.regularizers.l2(reg_penalty),\n",
    "                            name = \"Dense%02d\" % i))\n",
    "        else: #use implicit input shape\n",
    "            model.add(Dense(units = hidden_layer_size, \n",
    "                            activation = activation,\n",
    "                            kernel_initializer = keras.initializers.glorot_uniform(),\n",
    "                            kernel_regularizer=keras.regularizers.l2(reg_penalty),\n",
    "                            name = \"Dense%02d\" % i))\n",
    "\n",
    "        hidden_layer_size = hidden_layer_size // 2\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "\n",
    "    # reduce learning rate by 1/10 vs. default, we are calling repeatedly for 1 iteration\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_model(filename, verbose=True):\n",
    "    json_file = open('%s.json' % filename, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    mymodel = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    mymodel.load_weights(\"%s.h5\" % filename)\n",
    "    print(\"Loaded saved V_model\")\n",
    "    mymodel.compile(loss='mse', optimizer=Adam(learning_rate=0.00001), metrics=['mae'])\n",
    "    if verbose:\n",
    "        print(mymodel.summary())\n",
    "    return mymodel\n",
    "\n",
    "def save_model(filename, verbose=True):\n",
    "    # serialize model to JSON\n",
    "    model_json = V_model.to_json()\n",
    "    with open(\"%s.json\" % filename, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        V_model.save_weights(\"%s.h5\" % filename)\n",
    "    if verbose:\n",
    "        print(\"Saved '%s' to disk\" % filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# use DeepRLAgent\n",
    "# play a bunch of games computer v. computer and update V function approximator\n",
    "\n",
    "START_EXPLORATION_RATE = 0.04\n",
    "NUM_GAMES = 9999\n",
    "verbose = False\n",
    "\n",
    "V_hist_columns=['0','1','2','3','4','5','6','7','8','val']\n",
    "V_hist = pd.DataFrame(columns=V_hist_columns)\n",
    "\n",
    "best_metric=None\n",
    "best_model=None\n",
    "\n",
    "# V_model = build_ols_model(input_size = INPUT_DIM,\n",
    "#                            n_hidden_layers=3, \n",
    "#                            largest_layer_size=128,\n",
    "#                            activation='tanh',\n",
    "#                            reg_penalty=0.0,\n",
    "#                            dropout=0.0,\n",
    "#                            verbose=True)        \n",
    "\n",
    "# load best previous model\n",
    "V_model = load_model('model')\n",
    "    \n",
    "def play_game(V,\n",
    "              board_size=BOARD_SIZE,\n",
    "              exploration_rate=START_EXPLORATION_RATE,\n",
    "              train=True,\n",
    "              evaluate=False,\n",
    "              game_counter=0,\n",
    "              verbose=verbose):\n",
    "\n",
    "    g = Game()\n",
    "    global V_model, V_hist\n",
    "     \n",
    "    playerX = DeepRLagent(g, V_model, V_hist, 'X')\n",
    "    playerO = DeepRLagent(g, V_model, V_hist, 'O')\n",
    "    \n",
    "    max_moves = BOARD_SIZE * BOARD_SIZE\n",
    "    winner = None\n",
    "    #pdb.set_trace()\n",
    "    for move_counter in range(max_moves):        \n",
    "        player = g.player\n",
    "\n",
    "        move = playerX.select_move(verbose, exploration_rate=exploration_rate) if player == 'X' \\\n",
    "            else playerO.select_move(verbose, exploration_rate=exploration_rate)\n",
    "        g.play(move)\n",
    "        \n",
    "        if g.is_winner(player):\n",
    "            winner = player\n",
    "            break\n",
    "\n",
    "#     if winner is None:\n",
    "#         print(\"Draw\")\n",
    "#     else:\n",
    "#         print(\"%s wins!\" % winner)\n",
    "\n",
    "    if verbose:\n",
    "        for i, b in enumerate(g.history):\n",
    "            print(\"Move %d\" % i)\n",
    "            print(V[b])\n",
    "            print(print_board(b))\n",
    "        \n",
    "    # update V\n",
    "    if train:\n",
    "        playerO.train(initial_epoch=game_counter, evaluate=evaluate)\n",
    "    \n",
    "    return winner\n",
    "\n",
    "draw_count = 0\n",
    "draw_counts = []\n",
    "for game_counter in range(NUM_GAMES):\n",
    "    # linear epsilon decay\n",
    "    exploration_rate = (1 - game_counter/NUM_GAMES) * START_EXPLORATION_RATE\n",
    "\n",
    "    if game_counter % 100 == 0 and game_counter:\n",
    "        print(\"%s: Finished %6d Games, Draws in last 100 games: %d\" % (time.strftime(\"%H:%M:%S\"), game_counter, draw_count))\n",
    "        draw_counts.append(draw_count)\n",
    "        draw_count = 0\n",
    "        evaluate = True\n",
    "    else:\n",
    "        evaluate = False\n",
    "\n",
    "    winner = play_game(V_model, V_hist, exploration_rate=exploration_rate, train=True, evaluate=evaluate,\n",
    "                       game_counter=game_counter)\n",
    "        \n",
    "    if winner is None:\n",
    "        draw_count += 1\n",
    "        \n",
    "    print(\"%s: Game %d %s\" % (time.strftime(\"%H:%M:%S\"), game_counter,\n",
    "                              \"Draw\" if winner is None else \"%s wins!\" % winner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_model = load_model('model')\n",
    "\n",
    "while True:\n",
    "    g = Game()    \n",
    "    playerX = HumanAgent(g, 'X')\n",
    "    playerO = DeepRLagent(g, V_model, V_hist, 'O')\n",
    "    \n",
    "    max_moves = BOARD_SIZE * BOARD_SIZE\n",
    "    winner = None\n",
    "    \n",
    "    for _ in range(max_moves):\n",
    "        clear_output()\n",
    "        print(g)\n",
    "        \n",
    "        player = g.player\n",
    "        if player == 'X':\n",
    "            row, col = playerX.get_move()\n",
    "        else:\n",
    "            move = playerO.select_move(verbose=False, exploration_rate=0)            \n",
    "            g.play(move)\n",
    "\n",
    "        if g.is_winner(player):\n",
    "            winner = player\n",
    "            break\n",
    "\n",
    "    clear_output()\n",
    "    print(g)\n",
    "    if winner is None:\n",
    "        print(\"Draw\")\n",
    "    else:\n",
    "        print(\"%s wins!\" % winner)\n",
    "\n",
    "    if not play_again():\n",
    "        print(\"Bye!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
